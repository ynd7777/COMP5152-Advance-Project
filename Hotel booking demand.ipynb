{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7472bd",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "# 1. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad123d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"hotel_bookings.csv\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd09b8",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f99e6",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Check missing values in the data.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9322f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2ac05",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df['market_segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773b3ce",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def missing_percentage(df): \n",
    "    # A function for returning missing ratios.\n",
    "    \n",
    "    total_nan = df.isnull().sum()\n",
    "    total_nan_series = pd.Series(total_nan, index=df.columns)\n",
    "    total = total_nan_series.sort_values(ascending=False)\n",
    "\n",
    "    percent_nan = 100* df.isnull().sum() / len(df)\n",
    "    percent_nan_series = pd.Series(percent_nan, index=df.columns)\n",
    "    percent = percent_nan_series.sort_index(ascending=False)\n",
    "    \n",
    "    return pd.concat([total,percent],axis=1,keys=['Total','Percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abde345",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# checking 'NaN' values.\n",
    "\n",
    "missing = missing_percentage(df)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(20,5))\n",
    "sns.barplot(x=missing.index,y='Percent',data=missing,palette='Reds_r')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "display(missing.T.style.background_gradient(cmap='Reds',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a513c50",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Since 94% of rows are missing for company column, therefore, we drop the company column\n",
    "df = df.drop(['company'],axis=1)\n",
    "\n",
    "# The agent column has 13% missing values, we can either keep it or delete it. \n",
    "# By checking the metadata, agent column is the ID of the travel agency that made the booking, which is not relevant. \n",
    "# Therefore, we delete the agent column as well.\n",
    "df = df.drop(['agent'],axis=1)\n",
    "\n",
    "# A few of these features appear that it is just one or two rows missing the data, \n",
    "# it is more sense to drop a row, based on missing column features.\n",
    "df.dropna(subset=[\"children\",\"country\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400af4a9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Now, no more missing values in the dataset.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4798e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Check duplicated data.\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8be6cb4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicated data.\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742eb0c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Now, no more duplicated data, and our data cleaning process have been finished.\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813c5f5",
   "metadata": {},
   "source": [
    "# 2. Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9420e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Data Integrate (Feature Integration)\n",
    "# I wanted to label them manually. I will do the rest with get.dummies or label_encoder.\n",
    "df['hotel'] = df['hotel'].map({'Resort Hotel':0, 'City Hotel':1})\n",
    "\n",
    "df['arrival_date_month'] = df['arrival_date_month'].map({'January':1, 'February': 2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7,\n",
    "                                                            'August':8, 'September':9, 'October':10, 'November':11, 'December':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28a4f6",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def family(data):\n",
    "    if ((data['adults'] > 0) & (data['children'] > 0)):\n",
    "        val = 1\n",
    "    elif ((data['adults'] > 0) & (data['babies'] > 0)):\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820f2f7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def feature(df):\n",
    "    df[\"is_family\"] = df.apply(family, axis = 1)\n",
    "    df[\"total_customer\"] = df[\"adults\"] + df[\"children\"] + df[\"babies\"]\n",
    "    df[\"total_nights\"] = df[\"stays_in_weekend_nights\"]+ df[\"stays_in_week_nights\"]\n",
    "    return df\n",
    "\n",
    "df = feature(df)\n",
    "\n",
    "# Information of these columns is also inside of new features, so it is better to drop them.\n",
    "# I did not drop stays_nights features, I can't decide which feature is more important there.\n",
    "df = df.drop(columns = ['adults', 'babies', 'children', 'deposit_type', 'reservation_status_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd774245",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# correlation analysis (Heat map)\n",
    "plt.figure(figsize = (10,10)) \n",
    "correlation_df = df[df.columns].corr() \n",
    "mask = np.triu(correlation_df) \n",
    "sns.heatmap(correlation_df,mask = mask,cmap='coolwarm',annot=True,square = True,fmt='.1f',linewidths = 1)  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec1bbb",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cor_df = df.copy()\n",
    "le = LabelEncoder()\n",
    "# This data will not be used while predicting cancellation. This is just for checking correlation.\n",
    "cor_df['meal'] = le.fit_transform(cor_df['meal'])\n",
    "cor_df['distribution_channel'] = le.fit_transform(cor_df['distribution_channel'])\n",
    "cor_df['reserved_room_type'] = le.fit_transform(cor_df['reserved_room_type'])\n",
    "cor_df['assigned_room_type'] = le.fit_transform(cor_df['assigned_room_type'])\n",
    "cor_df['customer_type'] = le.fit_transform(cor_df['customer_type'])\n",
    "cor_df['reservation_status'] = le.fit_transform(cor_df['reservation_status'])\n",
    "cor_df['market_segment'] = le.fit_transform(cor_df['market_segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ce3ad",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# correlation analysis (Heat map)\n",
    "plt.figure(figsize = (15,15)) \n",
    "correlation_df = cor_df[cor_df.columns].corr()\n",
    "mask = np.triu(correlation_df) \n",
    "sns.heatmap(correlation_df,mask = mask,cmap='coolwarm',annot=True,square = True,fmt='.1f',linewidths = 1)  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96a43b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# get sorted correlation series of is_canceled column\n",
    "correlation_df_sorted = correlation_df[\"is_canceled\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077cc70",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# filter features with correlation's absolute value > 0.1\n",
    "important_feature_series = correlation_df_sorted[abs(correlation_df_sorted) > 0.1]\n",
    "target = 'is_canceled'\n",
    "important_features = important_feature_series.index.drop([target,'reservation_status'])\n",
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# final dataframe\n",
    "X = cor_df[important_features]\n",
    "y = cor_df[target]\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# We can use the functions to apply the models and roc curves to save space.\n",
    "def get_roc_curve(y_test, y_prob):\n",
    "    false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positive_rate, true_positive_rate, color = 'red', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1], linestyle = '--')\n",
    "    plt.axis('tight')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Model Evaluation\n",
    "## 3.1 Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# TODO: use graphviz to visualize the tree\n",
    "# TODO: Tuning the parameters by using GridCV\n",
    "# TODO: If speed is too slow, Cross-validation F1-score:{cross_val_score(clf, X, y, cv=10, scoring='f1').mean() can be deleted, this line is used to calculate the f1-score by cross-validation.\n",
    "clf = DecisionTreeClassifier(max_depth=20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pos_prob = clf.predict_proba(X_test)[:,1]\n",
    "print(\"Decision Tree Model:\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\nAccuracy Score:{accuracy_score(y_test,y_pred)}\\nRecall score:{recall_score(y_test,y_pred)}\\nPrecision Score:{precision_score(y_test, y_pred)}\\nF1-score:{f1_score(y_test,y_pred)}\\nCross-validation F1-score:{cross_val_score(clf, X, y, cv=10, scoring='f1').mean()}\")\n",
    "get_roc_curve(y_test,y_pos_prob)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# TODO: Tuning the parameters by using GridCV\n",
    "# TODO: If speed is too slow, Cross-validation F1-score:{cross_val_score(clf, X, y, cv=10, scoring='f1').mean() can be deleted, this line is used to calculate the f1-score by cross-validation.\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pos_prob = clf.predict_proba(X_test)[:,1]\n",
    "print(\"SVM Model:\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\nAccuracy Score:{accuracy_score(y_test,y_pred)}\\nRecall score:{recall_score(y_test,y_pred)}\\nPrecision Score:{precision_score(y_test, y_pred)}\\nF1-score:{f1_score(y_test,y_pred)}\")\n",
    "get_roc_curve(y_test,y_pos_prob)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# TODO: Tuning the parameters by using GridCV\n",
    "# TODO: If speed is too slow, Cross-validation F1-score:{cross_val_score(clf, X, y, cv=10, scoring='f1').mean() can be deleted, this line is used to calculate the f1-score by cross-validation.\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pos_prob = clf.predict_proba(X_test)[:,1]\n",
    "print(\"Random Forest Model:\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\nAccuracy Score:{accuracy_score(y_test,y_pred)}\\nRecall score:{recall_score(y_test,y_pred)}\\nPrecision Score:{precision_score(y_test, y_pred)}\\nF1-score:{f1_score(y_test,y_pred)}\\nCross-validation F1-score:{cross_val_score(clf, X, y, cv=10, scoring='f1-score').mean()}\")\n",
    "get_roc_curve(y_test,y_pos_prob)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4 XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# TODO: Tuning the parameters by using GridCV\n",
    "# TODO: If speed is too slow, Cross-validation F1-score:{cross_val_score(clf, X, y, cv=10, scoring='f1').mean() can be deleted, this line is used to calculate the f1-score by cross-validation.\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pos_prob = clf.predict_proba(X_test)[:,1]\n",
    "print(\"Random Forest Model:\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\nAccuracy Score:{accuracy_score(y_test,y_pred)}\\nRecall score:{recall_score(y_test,y_pred)}\\nPrecision Score:{precision_score(y_test, y_pred)}\\nF1-score:{f1_score(y_test,y_pred)}\\nCross-validation F1-score:{cross_val_score(clf, X, y, cv=10, scoring='f1-score').mean()}\")\n",
    "get_roc_curve(y_test,y_pos_prob)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
